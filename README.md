# airflow
Exemplo de uso do Airflow em DataOps

> https://www.youtube.com/watch?v=K9AnJ9_ZAXE
<br> <br>
> https://medium.com/agoda-engineering/orchestrating-airflow-tasks-with-docker-swarm-69b5fb2723a7
<br> <br>
> https://medium.com/analytics-vidhya/setting-up-airflow-to-run-with-docker-swarms-orchestration-b16459cd03a2
<br> <br>
> https://towardsdatascience.com/using-apache-airflow-dockeroperator-with-docker-compose-57d0217c8219
<br> <br>
> https://towardsdatascience.com/data-engineering-basics-of-apache-airflow-build-your-first-pipeline-eefecb7f1bb9
<br> <br>
> https://www.projectpro.io/recipes/schedule-dag-file-create-table-and-load-data-into-it-mysql-and-hive-airflow
<br> <br>
> https://www.projectpro.io/recipes/migrate-data-from-mysql-hive-using-airflow

<br> 

Providers:
> https://airflow.apache.org/docs/apache-airflow-providers-apache-hive/2.3.3/_api/airflow/providers/apache/hive/index.html

<br>

Consumindo dados do Hive via python:

> https://github.com/dropbox/PyHive
